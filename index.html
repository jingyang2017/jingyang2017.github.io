<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jing Yang</title>

  <meta name="author" content="Jing Yang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Jing Yang
                  </p>
                  <p>I am a Research Associate at <a href="https://core-lab.io/">Core LAB at University of
                      Cambridge</a>, where I work on GenAI with Prof. <a
                      href="https://scholar.google.ch/citations?hl=en&user=dXt1WOUAAAAJ&view_op=list_works&sortby=pubdate">Cengiz
                      √ñztireli</a>.
                  </p>
                  <p>
                    Before that, I received a PHD from the University of Nottingham under the supervision of Prof. <a
                      href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios (Yorgos)
                      Tzimiropoulos</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:y.jing2016@gmail.com">Email</a> &nbsp;/&nbsp;
                    <a href="https://scholar.google.co.uk/citations?user=a0HJYXcAAAAJ&hl=en">Google Scholar</a>
                    &nbsp;/&nbsp;
                    <a href="https://github.com/jingyang2017">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/profile_pic_crop.png" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <h2>Research  (selected publications)</h2>
                  <p>
                    I am interested in many areas of Computer Vision - my research focuses on deep face analysis and
                    model compression. Recently, I have been exploring the intersection of 3D Computer Vision, Computer
                    Graphics and Generative Models.
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/ALIP.jpeg' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">ALIP: Adaptive Language-Image Pre-training with Synthetic Caption</span>
                  </a>
                  <br>
                  <a href="">Kaicheng Yang</a>,
                  <a href="https://scholar.google.com/citations?user=Z_UoQFsAAAAJ&hl=zh-CN">Jiankang Deng</a>,
                  <a href="">Xiang An</a>,
                  <a href="">Jiawei Li</a>,
                  <a href="">Ziyong Feng</a>,
                  <a href="https://scholar.google.com/citations?user=H_-hMLUAAAAJ&hl=zh-CN">Jia Guo</a>,
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en">Tongliang Liu</a>

                  <br>
                  <em>ICCV</em>, 2023
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf">paper</a>
                  /
                  <a href="https://github.com/deepglint/ALIP">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/AUNet.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">Toward Robust Facial Action Units‚Äô Detection</span>
                  </a>
                  <br>
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=JNTNmT4AAAAJ&hl=en">Yordan Hristov</a>,
                  <a href="https://scholar.google.co.uk/citations?user=u8af3y8AAAAJ&hl=en">Jie Shen</a>,
                  <a href="https://scholar.google.co.uk/citations?user=Y5RfxWkAAAAJ&hl=en">Yiming Lin</a>,
                  <a href="https://scholar.google.co.uk/citations?user=ygpxbK8AAAAJ&hl=en">Maja Pantic</a>

                  <br>
                  <em>Proceedings of the IEEE</em>, 2023
                  <br>
                  <a
                    href="https://github.com/jingyang2017/AU-Net/blob/main/Towards%20Robust%20Facial%20Action%20Units%20Detection.pdf">paper</a>
                  /
                  <a href="https://github.com/jingyang2017/AU-Net/tree/main">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/FANTrans.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">FAN-Trans: Online Knowledge Distillation for Facial Action Unit
                    Detection</span>
                  </a>
                  <br>
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=u8af3y8AAAAJ&hl=en">Jie Shen</a>,
                  <a href="https://scholar.google.co.uk/citations?user=Y5RfxWkAAAAJ&hl=en">Yiming Lin</a>,
                  <a href="https://scholar.google.co.uk/citations?user=JNTNmT4AAAAJ&hl=en">Yordan Hristov</a>,
                  <a href="https://scholar.google.co.uk/citations?user=ygpxbK8AAAAJ&hl=en">Maja Pantic</a>

                  <br>
                  <em>WACV</em>, 2023
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content/WACV2023/html/Yang_FAN-Trans_Online_Knowledge_Distillation_for_Facial_Action_Unit_Detection_WACV_2023_paper.html">paper</a>
                  /
                  <a href="https://github.com/jingyang2017/AU-Net/tree/main">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/Unicom.png' width="160">
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle"></span> Unicom: Universal and Compact Representation Learning for Image
                    Retrieval </span>
                  </a>
                  <br>
                  <a href="">Xiang An</a>,
                  <a href="https://scholar.google.com/citations?user=Z_UoQFsAAAAJ&hl=zh-CN">Jiankang Deng</a>,
                  <a href="">Kaicheng Yang</a>,
                  <a href="">Ziyong Feng</a>,
                  <a href="https://scholar.google.com/citations?user=H_-hMLUAAAAJ&hl=zh-CN">Jia Guo</a>,
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en">Tongliang Liu</a>


                  <br>
                  <em>ICLR</em>, 2023
                  <br>
                  <a href="https://openreview.net/forum?id=3YFDsSRSxB-">paper</a>
                  /
                  <a href="https://github.com/deepglint/unicom">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/UFR.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">Pre-training strategies and datasets for facial representation
                    learning</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.co.uk/citations?user=5sKcsg0AAAAJ&hl=en">Adrian Bulat</a>,
                  <a href="https://scholar.google.com/citations?user=yIjMfQEAAAAJ&hl=zh-CN">Shiyang Cheng</a>,
                  <strong>Jing Yang</strong>,
                  <a href="">Andrew Garbett</a>,
                  <a href="https://scholar.google.co.uk/citations?user=VLIQpIYAAAAJ&hl=en">Enrique Sanchez</a>,
                  <a href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios Tzimiropoulos</a>

                  <br>
                  <em>ECCV</em>, 2022
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007/978-3-031-19778-9_7">paper</a>
                  /
                  <a href="https://github.com/1adrianb/unsupervised-face-representation">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/PartialFC.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">Killing Two Birds with One Stone:efficient and Robust Training of Face
                    Recognition CNNs by Partial FC</span>
                  </a>
                  <br>
                  <a href="">Xiang An</a>,

                  <a href="https://scholar.google.com/citations?user=Z_UoQFsAAAAJ&hl=zh-CN">Jiankang Deng</a>,
                  <a href="https://scholar.google.com/citations?user=H_-hMLUAAAAJ&hl=zh-CN">Jia Guo</a>,
                  <a href="">Ziyong Feng</a>,
                  <a href="">XuHan Zhu</a>,
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.com.au/citations?user=EiLdZ_YAAAAJ&hl=en">Tongliang Liu</a>


                  <br>
                  <em>CVPR</em>, 2022
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content/CVPR2022/html/An_Killing_Two_Birds_With_One_Stone_Efficient_and_Robust_Training_CVPR_2022_paper.html">paper</a>
                  /
                  <a href="https://github.com/deepinsight/ insightface/tree/master/recognition">code</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/SRRL.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">Knowledge distillation via softmax regression representation
                    learning</span>
                  </a>
                  <br>
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=5sKcsg0AAAAJ&hl=en">Adrian Bulat</a>,
                  <a href="https://scholar.google.co.uk/citations?user=-62MApgAAAAJ&hl=en">Brais Martinez</a>
                  <a href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios Tzimiropoulos</a>
                  <br>
                  <em>ICLR</em>, 2021
                  <br>
                  <a href="https://openreview.net/forum?id=ZzwDy_wiWv">paper</a>
                  /
                  <a href="https://github.com/jingyang2017/KD_SRRL">code</a>
                  /<a href="https://github.com/jingyang2017/SRD_ossl">extention</a>

                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/FANFace.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">FAN-Face: a Simple Orthogonal Improvement to Deep Face Recognition
                    learning</span>
                  </a>
                  <br>
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=5sKcsg0AAAAJ&hl=en">Adrian Bulat</a>,
                  <a href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios Tzimiropoulos</a>
                  <br>
                  <em>AAAI</em>, 2020
                  <br>
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6953">paper</a>
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/Real2Bin.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">Training binary neural networks with real-to-binary convolutions</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.co.uk/citations?user=-62MApgAAAAJ&hl=en">Brais Martinez</a>
                  <strong>Jing Yang</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=5sKcsg0AAAAJ&hl=en">Adrian Bulat</a>,
                  <a href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios Tzimiropoulos</a>
                  <br>
                  <em>ICLR</em>, 2020
                  <br>
                  <a href="https://openreview.net/forum?id=BJg4NgBKvH">paper</a>
                  /
                  <a href="https://github.com/brais-martinez/real2binary">code</a>

                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src='images/SR2018.png' width="160">
                </td>


                <td style="padding:20px;width:75%;vertical-align:middle">
                  <a <span class="papertitle">To learn image super-resolution, use a GAN to learn how to do image
                    degradation first</span>
                  </a>
                  <br>
                  <a href="https://scholar.google.co.uk/citations?user=5sKcsg0AAAAJ&hl=en">Adrian Bulat*</a>,
                  <strong>Jing Yang*</strong>,
                  <a href="https://scholar.google.co.uk/citations?user=D4JkWxf-8fwC&hl=en">Georgios Tzimiropoulos</a>
                  <br>
                  <em>ECCV</em>, 2018,*Equal contribution
                  <br>
                  <a
                    href="https://openaccess.thecvf.com/content_ECCV_2018/html/Adrian_Bulat_To_learn_image_ECCV_2018_paper.html">paper</a>
                  /
                  <a href="https://github.com/jingyang2017/Face-and-Image-super-resolution">code</a>

                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <div
                  style="width:100%;max-width:400px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <script type="text/javascript" id="clustrmaps"
                    src="//clustrmaps.com/map_v2.js?d=LJavhHQ7FyOc1V2GSkTohpaJjFJyVgVkgbE66z4Fqiw&cl=ffffff&w=a"></script>
                </div>
                <td>
                  Website inspired by <a href="https://jonbarron.info/">Jon Barron</a>.
                </td>
              </tr>
            </tbody>
          </table>

          <!-- <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:middle;font-size:small;">
                    Thank you to Jon Barron for the <a href="https://github.com/jonbarron/jonbarron_website">source
                      code</a> for the website!
                  </p>
                </td>
              </tr>
            </tbody>
          </table> -->
        </td>
      </tr>
  </table>
</body>

</html>