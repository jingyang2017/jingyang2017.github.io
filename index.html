<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title> </title>
        <link rel="stylesheet" href="./css/default.css" />
        <link rel="stylesheet" href="./css/syntax.css" />
        <link rel="shortcut icon" type="image/x-icon" href="./images/favicon.ico" />
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML,http://chaoxuprime.com/mathjax_conf.js">
        </script>

    </head>

    <body>

        <article role="main">
            <h1 id="article-title"> </h1>
            <br />

<h1>Jing Yang</h1>
<p>
Jing Yang is currently a Postdoctoral Researcher working with Prof. Cengiz Öztireli at University of Cambridge. Her current research interests lie at the intersection of Computer Vision and Machine Learning.
She achieved a Ph.D. at University of Nottingham, under the supervision of Prof. Georgios (Yorgos) Tzimiropoulos.
</p>
<p>
    More: <a href="https://scholar.google.co.uk/citations?user=a0HJYXcAAAAJ&hl=en">Google Scholar</a>, <a href="https://github.com/jingyang2017">Github</a>.
</p>
<h1>Newest Publications</h1>
<table class="postindex">
<ul>
        <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>ALIP: Adaptive Language-Image Pre-training with Synthetic Caption</strong></b></p>
                <p>Kaicheng Yang, Jiankang Deng, Xiang An, Jiawei Li, Ziyong Feng, Jia Guo, Jing Yang, Tongliang Liu</p>
                <p>ICCV, 2023</p>[<a href="https://arxiv.org/abs/2308.08428">pdf</a>] 
            </div>
        </div>
    </tr>

        <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Toward Robust Facial Action Units’ Detection</strong></b></p>
                <p>Jing Yang, Yordan Hristov, Jie Shen, Yiming Lin, Maja Pantic </p>
                <p>Proceedings of the IEEE, 2023</p>[<a href="https://ieeexplore.ieee.org/document/10081935
">pdf</a>] 
            </div>
        </div>
    </tr>
    
    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>FAN-Trans: Online Knowledge Distillation for Facial Action Unit Detection</strong></b></p>
                <p>Jing Yang; Jie Shen; Yiming Lin; Yordan Hristov; Maja Pantic </p>
                <p>WACV, 2023</p>[<a href="http://arxiv.org/abs/2211.06143">pdf</a>] 
            </div>
        </div>
    </tr>
    
    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Pre-training strategies and datasets for facial representation learning</strong></b></p>
                <p>Adrian Bulat; Shiyang Cheng; Jing Yang; Andrew Garbett; Enrique Sanchez; Georgios Tzimiropoulos</p>
                <p>ECCV, 2022</p>[<a href="https://www.adrianbulat.com/downloads/ECCV2022/face_representation_learning.pdf">pdf</a>]
            </div>
        </div>
    </tr>
    
    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Killing Two Birds with One Stone:efficient and Robust Training of Face Recognition CNNs by Partial FC</strong></b></p>
                <p>Xiang An;Jiankang Deng; Jia Guo; Ziyong Feng;XuHan Zhu;Jing Yang;Tongliang Liu</p>
                <p>CVPR, 2022</p>[<a href="https://arxiv.org/pdf/2203.15565.pdf">pdf</a>]
            </div>
        </div>
    </tr>
    
     <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>ArcFace: Additive Angular Margin Loss for Deep Face Recognition</strong></b></p>
                <p>Jiankang Deng; Jia Guo; Jing Yang; Niannan Xue; Irene Cotsia; Stefanos P Zafeiriou</p>
                <p>TPAMI, 2021</p>[<a href="https://ieeexplore.ieee.org/document/9449988">pdf</a>]
            </div>
        </div>
    </tr>
    
    
        <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Variational Prototype Learning for Deep Face Recognition</strong></b></p>
                <p>Deng, Jiankang and Guo, Jia and Yang, Jing and Lattas, Alexandros and Zafeiriou, Stefanos</p>
                <p>CVPR, 2021</p>[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Variational_Prototype_Learning_for_Deep_Face_Recognition_CVPR_2021_paper.pdf">pdf</a>]
            </div>
        </div>
    </tr>


    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Knowledge distillation via softmax regression representation learning</strong></b></p>
                <p>Jing Yang, Brais Marinez, Adrian Bulat, Georgios Tzimiropoulos</p>
                <p>ICLR, 2021</p>[<a href="https://openreview.net/forum?id=ZzwDy_wiWv">pdf</a>]
            </div>
        </div>
    </tr>


    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>FAN-Face: a Simple Orthogonal Improvement to Deep Face Recognition</strong></b></p>
                <p>Jing Yang, Adrian Bulat, Georgios Tzimiropoulos</p>
                <p>AAAI, 2020</p>[<a href="https://www.adrianbulat.com/downloads/AAAI20/FANFace.pdf">pdf</a>]
            </div>
        </div>
    </tr>

    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Training binary neural networks with real-to-binary convolutions</strong></b></p>
                <p>Brais Marinez, Jing Yang*, Adrian Bulat*, Georgios Tzimiropoulos</p>
                <p>ICLR, 2020</p>[<a href="https://arxiv.org/pdf/2003.11535.pdf">pdf</a>]
            </div>
        </div>
    </tr>

    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>To learn image super-resolution, use a GAN to learn how to do image degradation first</strong></b></p>
                <p>Adrian Bulat*, Jing Yang*, Georgios Tzimiropoulos</p>
                <p>ECCV, 2018</p>[<a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Adrian_Bulat_To_learn_image_ECCV_2018_paper.pdf">pdf</a>]
            </div>
        </div>
    </tr>

    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Stacked hourglass network for robust facial landmark localisation</strong></b></p>
                <p>Jing Yang, Qingshan Liu, Kaihua Zhang</p>
                <p>CVPRW, 2017 (Winner of Menpo Challenge)</p>[<a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w33/papers/Yang_Stacked_Hourglass_Network_CVPR_2017_paper.pdf">pdf</a>]
            </div>
        </div>
    </tr>
    
    <tr>
        <div class="row">
            <div class="col-md-12" style="margin-bottom: 0.2em;">
                <p><b><strong>Facial shape tracking via spatio- temporal cascade shape regression</strong></b></p>
                <p>Jing Yang, Jiankang Deng,Qingshan Liu, Kaihua Zhang</p>
                <p>ICCVW, 2015 (Winner of 300VW Challenge)</p>[<a href="https://www.cv-foundation.org//openaccess/content_iccv_2015_workshops/w25/papers/Yang_Facial_Shape_Tracking_ICCV_2015_paper.pdf">pdf</a>]
            </div>
        </div>
    </tr>



    </article>


    </body>
</html>
